/home/axs7716/my_model/Finetuning_V3_11-19-2025.py:23: UserWarning: WARNING: Unsloth should be imported before transformers to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.

Please restructure your imports with 'import unsloth' at the top of your file.
  import unsloth
2025-11-27 12:03:33.162345: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-27 12:03:33.209598: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-27 12:03:35.388732: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:01<00:05,  1.17s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.17s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.17s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.18s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:05<00:01,  1.16s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.02s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.10s/it]
Unsloth 2025.11.3 patched 80 layers with 80 QKV layers, 80 O layers and 80 MLP layers.
Unsloth: Already have LoRA adapters! We shall skip this step.
Map (num_proc=8):   0%|          | 0/181 [00:00<?, ? examples/s]Map (num_proc=8):  13%|█▎        | 23/181 [00:01<00:07, 19.79 examples/s]Map (num_proc=8):  25%|██▌       | 46/181 [00:01<00:03, 35.99 examples/s]Map (num_proc=8):  51%|█████     | 92/181 [00:01<00:01, 74.59 examples/s]Map (num_proc=8):  64%|██████▎   | 115/181 [00:01<00:00, 90.51 examples/s]Map (num_proc=8):  88%|████████▊ | 159/181 [00:02<00:00, 110.81 examples/s]Map (num_proc=8): 100%|██████████| 181/181 [00:02<00:00, 76.19 examples/s] 
Map (num_proc=8):   0%|          | 0/61 [00:00<?, ? examples/s]Map (num_proc=8):  13%|█▎        | 8/61 [00:01<00:06,  7.96 examples/s]Map (num_proc=8):  26%|██▌       | 16/61 [00:01<00:03, 14.18 examples/s]Map (num_proc=8):  39%|███▉      | 24/61 [00:01<00:01, 21.91 examples/s]Map (num_proc=8):  66%|██████▌   | 40/61 [00:01<00:00, 40.70 examples/s]Map (num_proc=8):  89%|████████▊ | 54/61 [00:01<00:00, 40.51 examples/s]Map (num_proc=8): 100%|██████████| 61/61 [00:02<00:00, 28.28 examples/s]
Using auto half precision backend
skipped Embedding(128256, 8192, padding_idx=128004): 1002.0M params
skipped: 1002.0M params
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 181 | Num Epochs = 10 | Total steps = 60
O^O/ \_/ \    Batch size per device = 8 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (8 x 4 x 1) = 32
 "-____-"     Trainable parameters = 103,546,880 of 70,657,253,376 (0.15% trained)
  0%|          | 0/60 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/axs7716/my_model/Finetuning_V3_11-19-2025.py", line 288, in <module>
    main(model_args, data_args, training_args)
  File "/home/axs7716/my_model/Finetuning_V3_11-19-2025.py", line 235, in main
    trainer.train(resume_from_checkpoint=None)
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/trl/trainer/sft_trainer.py", line 361, in train
    output = super().train(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 330, in _fast_inner_training_loop
  File "<string>", line 40, in _unsloth_training_step
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/unsloth/models/_utils.py", line 1625, in _unsloth_pre_compute_loss
    outputs = self._old_compute_loss(model, inputs, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 36, in compute_loss
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/accelerate/utils/operations.py", line 819, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/accelerate/utils/operations.py", line 807, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/unsloth/models/llama.py", line 1516, in PeftModel_fast_forward
    return self.base_model(
           ^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/peft/tuners/tuners_utils.py", line 308, in forward
    return self.model.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/unsloth/models/llama.py", line 1327, in _CausalLM_fast_forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/unsloth/models/llama.py", line 1105, in LlamaModel_fast_forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/transformers/modeling_layers.py", line 93, in __call__
    return self._gradient_checkpointing_func(partial(super().__call__, **kwargs), *args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/utils/checkpoint.py", line 496, in checkpoint
    return CheckpointFunction.apply(function, preserve, *args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/unsloth_zoo/gradient_checkpointing.py", line 484, in forward
    outputs = run_function(*args)
              ^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/unsloth/models/llama.py", line 744, in LlamaDecoderLayer_fast_forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/unsloth/kernels/fast_lora.py", line 240, in apply_lora_mlp_swiglu
    out = LoRA_MLP.apply(
          ^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/autograd/function.py", line 581, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/amp/autocast_mode.py", line 527, in decorate_fwd
    return fwd(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/unsloth/kernels/fast_lora.py", line 96, in forward
    i = matmul_lora(h, downW, downW_quant, downA, downB, downS)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/unsloth/kernels/utils.py", line 991, in matmul_lora
    out = torch_matmul(X, W, out = out)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.09 GiB. GPU 0 has a total capacity of 79.19 GiB of which 789.50 MiB is free. Including non-PyTorch memory, this process has 78.41 GiB memory in use. Of the allocated memory 77.64 GiB is allocated by PyTorch, and 36.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  0%|          | 0/60 [00:08<?, ?it/s]

/home/axs7716/my_model/Finetuning_V3_11-19-2025.py:23: UserWarning: WARNING: Unsloth should be imported before transformers to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.

Please restructure your imports with 'import unsloth' at the top of your file.
  import unsloth
2025-11-28 21:03:24.965500: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-28 21:03:25.013226: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-28 21:03:27.409468: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:01<00:05,  1.13s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.14s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.15s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.16s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:05<00:01,  1.15s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.01it/s]Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.07s/it]
Unsloth 2025.11.3 patched 80 layers with 80 QKV layers, 80 O layers and 80 MLP layers.
Unsloth: Already have LoRA adapters! We shall skip this step.
Using auto half precision backend
skipped Embedding(128256, 8192, padding_idx=128004): 1002.0M params
skipped: 1002.0M params
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 181 | Num Epochs = 10 | Total steps = 230
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 8
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 8 x 1) = 8
 "-____-"     Trainable parameters = 103,546,880 of 70,657,253,376 (0.15% trained)
  0%|          | 0/230 [00:00<?, ?it/s]  0%|          | 1/230 [00:51<3:17:18, 51.69s/it]                                                   0%|          | 1/230 [00:51<3:17:18, 51.69s/it]  1%|          | 2/230 [01:40<3:10:02, 50.01s/it]                                                   1%|          | 2/230 [01:40<3:10:02, 50.01s/it]  1%|▏         | 3/230 [02:30<3:08:47, 49.90s/it]                                                   1%|▏         | 3/230 [02:30<3:08:47, 49.90s/it]  2%|▏         | 4/230 [03:16<3:03:11, 48.64s/it]                                                   2%|▏         | 4/230 [03:16<3:03:11, 48.64s/it]  2%|▏         | 5/230 [04:06<3:04:01, 49.08s/it]                                                   2%|▏         | 5/230 [04:06<3:04:01, 49.08s/it]  3%|▎         | 6/230 [04:55<3:03:09, 49.06s/it]                                                   3%|▎         | 6/230 [04:55<3:03:09, 49.06s/it]  3%|▎         | 7/230 [05:43<3:00:35, 48.59s/it]                                                   3%|▎         | 7/230 [05:43<3:00:35, 48.59s/it]  3%|▎         | 8/230 [06:26<2:53:18, 46.84s/it]                                                   3%|▎         | 8/230 [06:26<2:53:18, 46.84s/it]  4%|▍         | 9/230 [07:14<2:53:45, 47.18s/it]                                                   4%|▍         | 9/230 [07:14<2:53:45, 47.18s/it]  4%|▍         | 10/230 [07:59<2:50:58, 46.63s/it]                                                    4%|▍         | 10/230 [07:59<2:50:58, 46.63s/it]  5%|▍         | 11/230 [08:51<2:55:32, 48.09s/it]                                                    5%|▍         | 11/230 [08:51<2:55:32, 48.09s/it]  5%|▌         | 12/230 [09:31<2:45:58, 45.68s/it]                                                    5%|▌         | 12/230 [09:31<2:45:58, 45.68s/it]  6%|▌         | 13/230 [10:17<2:45:36, 45.79s/it]                                                    6%|▌         | 13/230 [10:17<2:45:36, 45.79s/it]  6%|▌         | 14/230 [11:03<2:45:04, 45.85s/it]                                                    6%|▌         | 14/230 [11:03<2:45:04, 45.85s/it]  7%|▋         | 15/230 [11:46<2:41:12, 44.99s/it]                                                    7%|▋         | 15/230 [11:46<2:41:12, 44.99s/it]  7%|▋         | 16/230 [12:36<2:46:15, 46.61s/it]                                                    7%|▋         | 16/230 [12:36<2:46:15, 46.61s/it]  7%|▋         | 17/230 [13:23<2:45:48, 46.70s/it]                                                    7%|▋         | 17/230 [13:23<2:45:48, 46.70s/it]  8%|▊         | 18/230 [14:12<2:47:14, 47.33s/it]                                                    8%|▊         | 18/230 [14:12<2:47:14, 47.33s/it]  8%|▊         | 19/230 [15:04<2:51:30, 48.77s/it]                                                    8%|▊         | 19/230 [15:04<2:51:30, 48.77s/it]  9%|▊         | 20/230 [15:52<2:49:18, 48.37s/it]                                                    9%|▊         | 20/230 [15:52<2:49:18, 48.37s/it]  9%|▉         | 21/230 [16:42<2:50:43, 49.01s/it]                                                    9%|▉         | 21/230 [16:42<2:50:43, 49.01s/it] 10%|▉         | 22/230 [17:31<2:49:42, 48.95s/it]                                                   10%|▉         | 22/230 [17:31<2:49:42, 48.95s/it] 10%|█         | 23/230 [18:01<2:28:55, 43.17s/it]                                                   10%|█         | 23/230 [18:01<2:28:55, 43.17s/it] 10%|█         | 24/230 [18:49<2:33:46, 44.79s/it]                                                   10%|█         | 24/230 [18:49<2:33:46, 44.79s/it] 11%|█         | 25/230 [19:40<2:38:56, 46.52s/it]                                                   11%|█         | 25/230 [19:40<2:38:56, 46.52s/it] 11%|█▏        | 26/230 [20:27<2:39:21, 46.87s/it]                                                   11%|█▏        | 26/230 [20:27<2:39:21, 46.87s/it] 12%|█▏        | 27/230 [21:16<2:40:19, 47.39s/it]                                                   12%|█▏        | 27/230 [21:16<2:40:19, 47.39s/it] 12%|█▏        | 28/230 [22:02<2:37:39, 46.83s/it]                                                   12%|█▏        | 28/230 [22:02<2:37:39, 46.83s/it] 13%|█▎        | 29/230 [22:51<2:39:48, 47.70s/it]                                                   13%|█▎        | 29/230 [22:51<2:39:48, 47.70s/it] 13%|█▎        | 30/230 [23:36<2:36:10, 46.85s/it]                                                   13%|█▎        | 30/230 [23:36<2:36:10, 46.85s/it] 13%|█▎        | 31/230 [24:27<2:39:01, 47.95s/it]                                                   13%|█▎        | 31/230 [24:27<2:39:01, 47.95s/it] 14%|█▍        | 32/230 [25:13<2:36:07, 47.31s/it]                                                   14%|█▍        | 32/230 [25:13<2:36:07, 47.31s/it] 14%|█▍        | 33/230 [26:03<2:38:29, 48.27s/it]                                                   14%|█▍        | 33/230 [26:03<2:38:29, 48.27s/it] 15%|█▍        | 34/230 [26:53<2:38:54, 48.64s/it]                                                   15%|█▍        | 34/230 [26:53<2:38:54, 48.64s/it] 15%|█▌        | 35/230 [27:40<2:36:30, 48.15s/it]                                                   15%|█▌        | 35/230 [27:40<2:36:30, 48.15s/it] 16%|█▌        | 36/230 [28:28<2:36:19, 48.35s/it]                                                   16%|█▌        | 36/230 [28:28<2:36:19, 48.35s/it] 16%|█▌        | 37/230 [29:12<2:31:14, 47.02s/it]                                                   16%|█▌        | 37/230 [29:12<2:31:14, 47.02s/it] 17%|█▋        | 38/230 [29:56<2:27:23, 46.06s/it]                                                   17%|█▋        | 38/230 [29:56<2:27:23, 46.06s/it] 17%|█▋        | 39/230 [30:46<2:29:51, 47.08s/it]                                                   17%|█▋        | 39/230 [30:46<2:29:51, 47.08s/it] 17%|█▋        | 40/230 [31:32<2:28:27, 46.88s/it]                                                   17%|█▋        | 40/230 [31:32<2:28:27, 46.88s/it] 18%|█▊        | 41/230 [32:21<2:29:29, 47.46s/it]                                                   18%|█▊        | 41/230 [32:21<2:29:29, 47.46s/it] 18%|█▊        | 42/230 [33:06<2:26:49, 46.86s/it]                                                   18%|█▊        | 42/230 [33:06<2:26:49, 46.86s/it] 19%|█▊        | 43/230 [33:52<2:25:10, 46.58s/it]                                                   19%|█▊        | 43/230 [33:52<2:25:10, 46.58s/it] 19%|█▉        | 44/230 [34:38<2:23:57, 46.44s/it]                                                   19%|█▉        | 44/230 [34:38<2:23:57, 46.44s/it] 20%|█▉        | 45/230 [35:26<2:24:37, 46.90s/it]                                                   20%|█▉        | 45/230 [35:26<2:24:37, 46.90s/it] 20%|██        | 46/230 [35:57<2:08:55, 42.04s/it]                                                   20%|██        | 46/230 [35:57<2:08:55, 42.04s/it] 20%|██        | 47/230 [36:47<2:15:46, 44.52s/it]                                                   20%|██        | 47/230 [36:47<2:15:46, 44.52s/it] 21%|██        | 48/230 [37:36<2:18:25, 45.63s/it]                                                   21%|██        | 48/230 [37:36<2:18:25, 45.63s/it] 21%|██▏       | 49/230 [38:23<2:19:34, 46.27s/it]                                                   21%|██▏       | 49/230 [38:23<2:19:34, 46.27s/it] 22%|██▏       | 50/230 [39:13<2:22:04, 47.36s/it]                                                   22%|██▏       | 50/230 [39:13<2:22:04, 47.36s/it] 22%|██▏       | 51/230 [40:00<2:21:05, 47.29s/it]                                                   22%|██▏       | 51/230 [40:00<2:21:05, 47.29s/it] 23%|██▎       | 52/230 [40:42<2:15:04, 45.53s/it]                                                   23%|██▎       | 52/230 [40:42<2:15:04, 45.53s/it] 23%|██▎       | 53/230 [41:30<2:16:26, 46.25s/it]                                                   23%|██▎       | 53/230 [41:30<2:16:26, 46.25s/it] 23%|██▎       | 54/230 [42:19<2:18:31, 47.23s/it]                                                   23%|██▎       | 54/230 [42:19<2:18:31, 47.23s/it] 24%|██▍       | 55/230 [43:07<2:18:27, 47.47s/it]                                                   24%|██▍       | 55/230 [43:07<2:18:27, 47.47s/it] 24%|██▍       | 56/230 [43:55<2:17:39, 47.47s/it]                                                   24%|██▍       | 56/230 [43:55<2:17:39, 47.47s/it] 25%|██▍       | 57/230 [44:41<2:16:19, 47.28s/it]                                                   25%|██▍       | 57/230 [44:41<2:16:19, 47.28s/it] 25%|██▌       | 58/230 [45:29<2:15:56, 47.42s/it]                                                   25%|██▌       | 58/230 [45:29<2:15:56, 47.42s/it] 26%|██▌       | 59/230 [46:17<2:15:45, 47.64s/it]                                                   26%|██▌       | 59/230 [46:17<2:15:45, 47.64s/it] 26%|██▌       | 60/230 [47:06<2:16:08, 48.05s/it]                                                   26%|██▌       | 60/230 [47:06<2:16:08, 48.05s/it] 27%|██▋       | 61/230 [47:50<2:11:41, 46.75s/it]                                                   27%|██▋       | 61/230 [47:50<2:11:41, 46.75s/it] 27%|██▋       | 62/230 [48:40<2:13:19, 47.62s/it]                                                   27%|██▋       | 62/230 [48:40<2:13:19, 47.62s/it] 27%|██▋       | 63/230 [49:26<2:11:11, 47.14s/it]                                                   27%|██▋       | 63/230 [49:26<2:11:11, 47.14s/it] 28%|██▊       | 64/230 [50:16<2:12:36, 47.93s/it]                                                   28%|██▊       | 64/230 [50:16<2:12:36, 47.93s/it] 28%|██▊       | 65/230 [51:04<2:12:02, 48.02s/it]                                                   28%|██▊       | 65/230 [51:04<2:12:02, 48.02s/it] 29%|██▊       | 66/230 [51:49<2:08:38, 47.07s/it]                                                   29%|██▊       | 66/230 [51:49<2:08:38, 47.07s/it] 29%|██▉       | 67/230 [52:35<2:07:40, 47.00s/it]                                                   29%|██▉       | 67/230 [52:35<2:07:40, 47.00s/it] 30%|██▉       | 68/230 [53:23<2:07:29, 47.22s/it]                                                   30%|██▉       | 68/230 [53:23<2:07:29, 47.22s/it] 30%|███       | 69/230 [53:54<1:53:08, 42.16s/it]                                                   30%|███       | 69/230 [53:54<1:53:08, 42.16s/it] 30%|███       | 70/230 [54:42<1:57:25, 44.03s/it]                                                   30%|███       | 70/230 [54:42<1:57:25, 44.03s/it] 31%|███       | 71/230 [55:30<1:59:51, 45.23s/it]                                                   31%|███       | 71/230 [55:30<1:59:51, 45.23s/it] 31%|███▏      | 72/230 [56:17<2:00:28, 45.75s/it]                                                   31%|███▏      | 72/230 [56:17<2:00:28, 45.75s/it] 32%|███▏      | 73/230 [57:01<1:58:00, 45.10s/it]                                                   32%|███▏      | 73/230 [57:01<1:58:00, 45.10s/it] 32%|███▏      | 74/230 [57:48<1:59:07, 45.82s/it]                                                   32%|███▏      | 74/230 [57:48<1:59:07, 45.82s/it] 33%|███▎      | 75/230 [58:39<2:02:10, 47.30s/it]                                                   33%|███▎      | 75/230 [58:39<2:02:10, 47.30s/it] 33%|███▎      | 76/230 [59:27<2:02:02, 47.55s/it]                                                   33%|███▎      | 76/230 [59:27<2:02:02, 47.55s/it] 33%|███▎      | 77/230 [1:00:14<2:01:01, 47.46s/it]                                                     33%|███▎      | 77/230 [1:00:14<2:01:01, 47.46s/it] 34%|███▍      | 78/230 [1:01:02<2:00:12, 47.45s/it]                                                     34%|███▍      | 78/230 [1:01:02<2:00:12, 47.45s/it] 34%|███▍      | 79/230 [1:01:49<1:59:03, 47.31s/it]                                                     34%|███▍      | 79/230 [1:01:49<1:59:03, 47.31s/it] 35%|███▍      | 80/230 [1:02:34<1:56:35, 46.64s/it]                                                     35%|███▍      | 80/230 [1:02:34<1:56:35, 46.64s/it] 35%|███▌      | 81/230 [1:03:23<1:58:07, 47.57s/it]                                                     35%|███▌      | 81/230 [1:03:23<1:58:07, 47.57s/it] 36%|███▌      | 82/230 [1:04:10<1:56:16, 47.14s/it]                                                     36%|███▌      | 82/230 [1:04:10<1:56:16, 47.14s/it] 36%|███▌      | 83/230 [1:04:53<1:52:52, 46.07s/it]                                                     36%|███▌      | 83/230 [1:04:53<1:52:52, 46.07s/it] 37%|███▋      | 84/230 [1:05:44<1:55:42, 47.55s/it]                                                     37%|███▋      | 84/230 [1:05:44<1:55:42, 47.55s/it] 37%|███▋      | 85/230 [1:06:31<1:54:41, 47.46s/it]                                                     37%|███▋      | 85/230 [1:06:31<1:54:41, 47.46s/it] 37%|███▋      | 86/230 [1:07:18<1:53:30, 47.29s/it]                                                     37%|███▋      | 86/230 [1:07:18<1:53:30, 47.29s/it] 38%|███▊      | 87/230 [1:08:08<1:54:30, 48.04s/it]                                                     38%|███▊      | 87/230 [1:08:08<1:54:30, 48.04s/it] 38%|███▊      | 88/230 [1:08:56<1:53:32, 47.98s/it]                                                     38%|███▊      | 88/230 [1:08:56<1:53:32, 47.98s/it] 39%|███▊      | 89/230 [1:09:40<1:50:11, 46.89s/it]                                                     39%|███▊      | 89/230 [1:09:40<1:50:11, 46.89s/it] 39%|███▉      | 90/230 [1:10:30<1:51:31, 47.79s/it]                                                     39%|███▉      | 90/230 [1:10:30<1:51:31, 47.79s/it] 40%|███▉      | 91/230 [1:11:20<1:52:03, 48.37s/it]                                                     40%|███▉      | 91/230 [1:11:20<1:52:03, 48.37s/it] 40%|████      | 92/230 [1:11:50<1:38:56, 43.02s/it]                                                     40%|████      | 92/230 [1:11:50<1:38:56, 43.02s/it] 40%|████      | 93/230 [1:12:38<1:41:19, 44.38s/it]                                                     40%|████      | 93/230 [1:12:38<1:41:19, 44.38s/it] 41%|████      | 94/230 [1:13:27<1:43:38, 45.73s/it]                                                     41%|████      | 94/230 [1:13:27<1:43:38, 45.73s/it] 41%|████▏     | 95/230 [1:14:17<1:45:59, 47.10s/it]                                                     41%|████▏     | 95/230 [1:14:17<1:45:59, 47.10s/it] 42%|████▏     | 96/230 [1:15:07<1:47:19, 48.06s/it]                                                     42%|████▏     | 96/230 [1:15:07<1:47:19, 48.06s/it] 42%|████▏     | 97/230 [1:15:57<1:47:13, 48.37s/it]                                                     42%|████▏     | 97/230 [1:15:57<1:47:13, 48.37s/it] 43%|████▎     | 98/230 [1:16:42<1:44:48, 47.64s/it]                                                     43%|████▎     | 98/230 [1:16:42<1:44:48, 47.64s/it] 43%|████▎     | 99/230 [1:17:31<1:44:18, 47.77s/it]                                                     43%|████▎     | 99/230 [1:17:31<1:44:18, 47.77s/it] 43%|████▎     | 100/230 [1:18:19<1:43:47, 47.91s/it]                                                      43%|████▎     | 100/230 [1:18:19<1:43:47, 47.91s/it]Saving model checkpoint to /scratch/axs7716Arshcentaur-ptsd-finetuned_5e-05_7264_1_1_8_0.01_10/checkpoint-100
loading configuration file config.json from cache at /home/axs7716/.cache/huggingface/hub/models--unsloth--Meta-Llama-3.1-70B-bnb-4bit/snapshots/a009b8db2439814febe725486a5ed388f12a8744/config.json
Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "dtype": "bfloat16",
  "eos_token_id": 128001,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 8192,
  "initializer_range": 0.02,
  "intermediate_size": 28672,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 64,
  "num_hidden_layers": 80,
  "num_key_value_heads": 8,
  "pad_token_id": 128004,
  "pretraining_tp": 1,
  "quantization_config": {
    "_load_in_4bit": true,
    "_load_in_8bit": false,
    "bnb_4bit_compute_dtype": "bfloat16",
    "bnb_4bit_quant_storage": "uint8",
    "bnb_4bit_quant_type": "nf4",
    "bnb_4bit_use_double_quant": true,
    "llm_int8_enable_fp32_cpu_offload": false,
    "llm_int8_has_fp16_weight": false,
    "llm_int8_skip_modules": null,
    "llm_int8_threshold": 6.0,
    "load_in_4bit": true,
    "load_in_8bit": false,
    "quant_method": "bitsandbytes"
  },
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 8.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "unsloth_version": "2024.9",
  "use_cache": true,
  "vocab_size": 128256
}

 44%|████▍     | 101/230 [1:19:03<1:40:46, 46.87s/it]                                                      44%|████▍     | 101/230 [1:19:03<1:40:46, 46.87s/it] 44%|████▍     | 102/230 [1:19:50<1:39:53, 46.83s/it]                                                      44%|████▍     | 102/230 [1:19:50<1:39:53, 46.83s/it] 45%|████▍     | 103/230 [1:20:38<1:39:48, 47.15s/it]                                                      45%|████▍     | 103/230 [1:20:38<1:39:48, 47.15s/it] 45%|████▌     | 104/230 [1:21:23<1:37:41, 46.52s/it]                                                      45%|████▌     | 104/230 [1:21:23<1:37:41, 46.52s/it] 46%|████▌     | 105/230 [1:22:04<1:33:26, 44.85s/it]                                                      46%|████▌     | 105/230 [1:22:04<1:33:26, 44.85s/it] 46%|████▌     | 106/230 [1:22:54<1:36:11, 46.55s/it]                                                      46%|████▌     | 106/230 [1:22:54<1:36:11, 46.55s/it] 47%|████▋     | 107/230 [1:23:44<1:37:20, 47.48s/it]                                                      47%|████▋     | 107/230 [1:23:44<1:37:20, 47.48s/it] 47%|████▋     | 108/230 [1:24:31<1:36:00, 47.22s/it]                                                      47%|████▋     | 108/230 [1:24:31<1:36:00, 47.22s/it] 47%|████▋     | 109/230 [1:25:21<1:37:11, 48.20s/it]                                                      47%|████▋     | 109/230 [1:25:21<1:37:11, 48.20s/it] 48%|████▊     | 110/230 [1:26:08<1:35:37, 47.81s/it]                                                      48%|████▊     | 110/230 [1:26:08<1:35:37, 47.81s/it] 48%|████▊     | 111/230 [1:26:52<1:32:45, 46.77s/it]                                                      48%|████▊     | 111/230 [1:26:52<1:32:45, 46.77s/it] 49%|████▊     | 112/230 [1:27:41<1:33:05, 47.33s/it]                                                      49%|████▊     | 112/230 [1:27:41<1:33:05, 47.33s/it] 49%|████▉     | 113/230 [1:28:32<1:34:15, 48.34s/it]                                                      49%|████▉     | 113/230 [1:28:32<1:34:15, 48.34s/it] 50%|████▉     | 114/230 [1:29:18<1:32:01, 47.60s/it]                                                      50%|████▉     | 114/230 [1:29:18<1:32:01, 47.60s/it] 50%|█████     | 115/230 [1:29:48<1:21:27, 42.50s/it]                                                      50%|█████     | 115/230 [1:29:48<1:21:27, 42.50s/it] 50%|█████     | 116/230 [1:30:36<1:23:33, 43.98s/it]                                                      50%|█████     | 116/230 [1:30:36<1:23:33, 43.98s/it] 51%|█████     | 117/230 [1:31:25<1:25:50, 45.58s/it]                                                      51%|█████     | 117/230 [1:31:25<1:25:50, 45.58s/it] 51%|█████▏    | 118/230 [1:32:10<1:24:54, 45.49s/it]                                                      51%|█████▏    | 118/230 [1:32:10<1:24:54, 45.49s/it] 52%|█████▏    | 119/230 [1:33:00<1:26:20, 46.67s/it]                                                      52%|█████▏    | 119/230 [1:33:00<1:26:20, 46.67s/it] 52%|█████▏    | 120/230 [1:33:47<1:25:56, 46.88s/it]                                                      52%|█████▏    | 120/230 [1:33:47<1:25:56, 46.88s/it] 53%|█████▎    | 121/230 [1:34:33<1:24:51, 46.71s/it]                                                      53%|█████▎    | 121/230 [1:34:33<1:24:51, 46.71s/it] 53%|█████▎    | 122/230 [1:35:25<1:26:35, 48.10s/it]                                                      53%|█████▎    | 122/230 [1:35:25<1:26:35, 48.10s/it] 53%|█████▎    | 123/230 [1:36:16<1:27:31, 49.08s/it]                                                      53%|█████▎    | 123/230 [1:36:16<1:27:31, 49.08s/it] 54%|█████▍    | 124/230 [1:37:01<1:24:36, 47.90s/it]                                                      54%|█████▍    | 124/230 [1:37:01<1:24:36, 47.90s/it] 54%|█████▍    | 125/230 [1:37:49<1:24:02, 48.03s/it]                                                      54%|█████▍    | 125/230 [1:37:49<1:24:02, 48.03s/it] 55%|█████▍    | 126/230 [1:38:37<1:23:00, 47.89s/it]                                                      55%|█████▍    | 126/230 [1:38:37<1:23:00, 47.89s/it] 55%|█████▌    | 127/230 [1:39:27<1:23:10, 48.46s/it]                                                      55%|█████▌    | 127/230 [1:39:27<1:23:10, 48.46s/it] 56%|█████▌    | 128/230 [1:40:12<1:20:57, 47.63s/it]                                                      56%|█████▌    | 128/230 [1:40:12<1:20:57, 47.63s/it] 56%|█████▌    | 129/230 [1:40:59<1:19:35, 47.28s/it]                                                      56%|█████▌    | 129/230 [1:40:59<1:19:35, 47.28s/it] 57%|█████▋    | 130/230 [1:41:49<1:20:13, 48.14s/it]                                                      57%|█████▋    | 130/230 [1:41:49<1:20:13, 48.14s/it] 57%|█████▋    | 131/230 [1:42:35<1:18:13, 47.41s/it]                                                      57%|█████▋    | 131/230 [1:42:35<1:18:13, 47.41s/it] 57%|█████▋    | 132/230 [1:43:21<1:16:50, 47.05s/it]                                                      57%|█████▋    | 132/230 [1:43:21<1:16:50, 47.05s/it] 58%|█████▊    | 133/230 [1:44:04<1:14:05, 45.83s/it]                                                      58%|█████▊    | 133/230 [1:44:04<1:14:05, 45.83s/it] 58%|█████▊    | 134/230 [1:44:52<1:14:30, 46.57s/it]                                                      58%|█████▊    | 134/230 [1:44:52<1:14:30, 46.57s/it] 59%|█████▊    | 135/230 [1:45:42<1:15:08, 47.46s/it]                                                      59%|█████▊    | 135/230 [1:45:42<1:15:08, 47.46s/it] 59%|█████▉    | 136/230 [1:46:25<1:12:18, 46.15s/it]                                                      59%|█████▉    | 136/230 [1:46:25<1:12:18, 46.15s/it] 60%|█████▉    | 137/230 [1:47:14<1:12:53, 47.02s/it]                                                      60%|█████▉    | 137/230 [1:47:14<1:12:53, 47.02s/it] 60%|██████    | 138/230 [1:47:45<1:04:58, 42.37s/it]                                                      60%|██████    | 138/230 [1:47:45<1:04:58, 42.37s/it] 60%|██████    | 139/230 [1:48:37<1:08:15, 45.01s/it]                                                      60%|██████    | 139/230 [1:48:37<1:08:15, 45.01s/it] 61%|██████    | 140/230 [1:49:22<1:07:39, 45.10s/it]                                                      61%|██████    | 140/230 [1:49:22<1:07:39, 45.10s/it] 61%|██████▏   | 141/230 [1:50:07<1:07:02, 45.19s/it]                                                      61%|██████▏   | 141/230 [1:50:07<1:07:02, 45.19s/it] 62%|██████▏   | 142/230 [1:50:57<1:08:18, 46.57s/it]                                                      62%|██████▏   | 142/230 [1:50:57<1:08:18, 46.57s/it] 62%|██████▏   | 143/230 [1:51:45<1:07:55, 46.85s/it]                                                      62%|██████▏   | 143/230 [1:51:45<1:07:55, 46.85s/it] 63%|██████▎   | 144/230 [1:52:34<1:08:21, 47.69s/it]                                                      63%|██████▎   | 144/230 [1:52:34<1:08:21, 47.69s/it] 63%|██████▎   | 145/230 [1:53:24<1:08:28, 48.33s/it]                                                      63%|██████▎   | 145/230 [1:53:24<1:08:28, 48.33s/it] 63%|██████▎   | 146/230 [1:54:11<1:07:06, 47.93s/it]                                                      63%|██████▎   | 146/230 [1:54:11<1:07:06, 47.93s/it] 64%|██████▍   | 147/230 [1:54:59<1:06:10, 47.84s/it]                                                      64%|██████▍   | 147/230 [1:54:59<1:06:10, 47.84s/it] 64%|██████▍   | 148/230 [1:55:44<1:04:30, 47.20s/it]                                                      64%|██████▍   | 148/230 [1:55:44<1:04:30, 47.20s/it] 65%|██████▍   | 149/230 [1:56:33<1:04:25, 47.73s/it]                                                      65%|██████▍   | 149/230 [1:56:33<1:04:25, 47.73s/it] 65%|██████▌   | 150/230 [1:57:21<1:03:38, 47.73s/it]                                                      65%|██████▌   | 150/230 [1:57:21<1:03:38, 47.73s/it] 66%|██████▌   | 151/230 [1:58:05<1:01:28, 46.69s/it]                                                      66%|██████▌   | 151/230 [1:58:05<1:01:28, 46.69s/it] 66%|██████▌   | 152/230 [1:58:53<1:00:52, 46.83s/it]                                                      66%|██████▌   | 152/230 [1:58:53<1:00:52, 46.83s/it] 67%|██████▋   | 153/230 [1:59:41<1:00:35, 47.21s/it]                                                      67%|██████▋   | 153/230 [1:59:41<1:00:35, 47.21s/it] 67%|██████▋   | 154/230 [2:00:31<1:01:00, 48.16s/it]                                                      67%|██████▋   | 154/230 [2:00:31<1:01:00, 48.16s/it] 67%|██████▋   | 155/230 [2:01:22<1:01:07, 48.89s/it]                                                      67%|██████▋   | 155/230 [2:01:22<1:01:07, 48.89s/it] 68%|██████▊   | 156/230 [2:02:10<1:00:00, 48.66s/it]                                                      68%|██████▊   | 156/230 [2:02:10<1:00:00, 48.66s/it] 68%|██████▊   | 157/230 [2:02:53<57:05, 46.92s/it]                                                      68%|██████▊   | 157/230 [2:02:53<57:05, 46.92s/it] 69%|██████▊   | 158/230 [2:03:39<55:58, 46.65s/it]                                                    69%|██████▊   | 158/230 [2:03:39<55:58, 46.65s/it] 69%|██████▉   | 159/230 [2:04:28<56:18, 47.59s/it]                                                    69%|██████▉   | 159/230 [2:04:28<56:18, 47.59s/it] 70%|██████▉   | 160/230 [2:05:11<53:51, 46.17s/it]                                                    70%|██████▉   | 160/230 [2:05:11<53:51, 46.17s/it] 70%|███████   | 161/230 [2:05:43<48:02, 41.77s/it]                                                    70%|███████   | 161/230 [2:05:43<48:02, 41.77s/it] 70%|███████   | 162/230 [2:06:32<49:49, 43.96s/it]                                                    70%|███████   | 162/230 [2:06:32<49:49, 43.96s/it] 71%|███████   | 163/230 [2:07:21<50:45, 45.45s/it]                                                    71%|███████   | 163/230 [2:07:21<50:45, 45.45s/it] 71%|███████▏  | 164/230 [2:08:09<51:00, 46.37s/it]                                                    71%|███████▏  | 164/230 [2:08:09<51:00, 46.37s/it] 72%|███████▏  | 165/230 [2:08:59<51:19, 47.38s/it]                                                    72%|███████▏  | 165/230 [2:08:59<51:19, 47.38s/it] 72%|███████▏  | 166/230 [2:09:47<50:37, 47.46s/it]                                                    72%|███████▏  | 166/230 [2:09:47<50:37, 47.46s/it] 73%|███████▎  | 167/230 [2:10:36<50:28, 48.08s/it]                                                    73%|███████▎  | 167/230 [2:10:36<50:28, 48.08s/it] 73%|███████▎  | 168/230 [2:11:23<49:10, 47.60s/it]                                                    73%|███████▎  | 168/230 [2:11:23<49:10, 47.60s/it] 73%|███████▎  | 169/230 [2:12:07<47:30, 46.74s/it]                                                    73%|███████▎  | 169/230 [2:12:07<47:30, 46.74s/it] 74%|███████▍  | 170/230 [2:12:56<47:22, 47.37s/it]                                                    74%|███████▍  | 170/230 [2:12:56<47:22, 47.37s/it] 74%|███████▍  | 171/230 [2:13:39<45:18, 46.08s/it]                                                    74%|███████▍  | 171/230 [2:13:39<45:18, 46.08s/it] 75%|███████▍  | 172/230 [2:14:22<43:37, 45.13s/it]                                                    75%|███████▍  | 172/230 [2:14:22<43:37, 45.13s/it] 75%|███████▌  | 173/230 [2:15:11<44:02, 46.36s/it]                                                    75%|███████▌  | 173/230 [2:15:11<44:02, 46.36s/it] 76%|███████▌  | 174/230 [2:16:01<44:03, 47.21s/it]                                                    76%|███████▌  | 174/230 [2:16:01<44:03, 47.21s/it] 76%|███████▌  | 175/230 [2:16:43<41:58, 45.78s/it]                                                    76%|███████▌  | 175/230 [2:16:43<41:58, 45.78s/it] 77%|███████▋  | 176/230 [2:17:31<41:50, 46.49s/it]                                                    77%|███████▋  | 176/230 [2:17:31<41:50, 46.49s/it] 77%|███████▋  | 177/230 [2:18:14<39:57, 45.24s/it]                                                    77%|███████▋  | 177/230 [2:18:14<39:57, 45.24s/it] 77%|███████▋  | 178/230 [2:18:58<39:04, 45.09s/it]                                                    77%|███████▋  | 178/230 [2:18:58<39:04, 45.09s/it] 78%|███████▊  | 179/230 [2:19:48<39:30, 46.48s/it]                                                    78%|███████▊  | 179/230 [2:19:48<39:30, 46.48s/it] 78%|███████▊  | 180/230 [2:20:39<39:56, 47.94s/it]                                                    78%|███████▊  | 180/230 [2:20:39<39:56, 47.94s/it] 79%|███████▊  | 181/230 [2:21:32<40:10, 49.20s/it]                                                    79%|███████▊  | 181/230 [2:21:32<40:10, 49.20s/it] 79%|███████▉  | 182/230 [2:22:20<39:15, 49.07s/it]                                                    79%|███████▉  | 182/230 [2:22:20<39:15, 49.07s/it] 80%|███████▉  | 183/230 [2:23:07<37:57, 48.45s/it]                                                    80%|███████▉  | 183/230 [2:23:07<37:57, 48.45s/it] 80%|████████  | 184/230 [2:23:40<33:26, 43.63s/it]                                                    80%|████████  | 184/230 [2:23:40<33:26, 43.63s/it] 80%|████████  | 185/230 [2:24:28<33:48, 45.08s/it]                                                    80%|████████  | 185/230 [2:24:28<33:48, 45.08s/it] 81%|████████  | 186/230 [2:25:17<33:55, 46.26s/it]                                                    81%|████████  | 186/230 [2:25:17<33:55, 46.26s/it] 81%|████████▏ | 187/230 [2:26:05<33:24, 46.62s/it]                                                    81%|████████▏ | 187/230 [2:26:05<33:24, 46.62s/it] 82%|████████▏ | 188/230 [2:26:55<33:27, 47.79s/it]                                                    82%|████████▏ | 188/230 [2:26:55<33:27, 47.79s/it] 82%|████████▏ | 189/230 [2:27:44<32:55, 48.18s/it]                                                    82%|████████▏ | 189/230 [2:27:44<32:55, 48.18s/it] 83%|████████▎ | 190/230 [2:28:33<32:12, 48.31s/it]                                                    83%|████████▎ | 190/230 [2:28:33<32:12, 48.31s/it] 83%|████████▎ | 191/230 [2:29:13<29:47, 45.84s/it]                                                    83%|████████▎ | 191/230 [2:29:13<29:47, 45.84s/it] 83%|████████▎ | 192/230 [2:30:03<29:48, 47.07s/it]                                                    83%|████████▎ | 192/230 [2:30:03<29:48, 47.07s/it] 84%|████████▍ | 193/230 [2:30:47<28:25, 46.09s/it]                                                    84%|████████▍ | 193/230 [2:30:47<28:25, 46.09s/it] 84%|████████▍ | 194/230 [2:31:35<28:01, 46.71s/it]                                                    84%|████████▍ | 194/230 [2:31:35<28:01, 46.71s/it] 85%|████████▍ | 195/230 [2:32:25<27:55, 47.86s/it]                                                    85%|████████▍ | 195/230 [2:32:25<27:55, 47.86s/it] 85%|████████▌ | 196/230 [2:33:16<27:34, 48.65s/it]                                                    85%|████████▌ | 196/230 [2:33:16<27:34, 48.65s/it] 86%|████████▌ | 197/230 [2:34:01<26:10, 47.60s/it]                                                    86%|████████▌ | 197/230 [2:34:01<26:10, 47.60s/it] 86%|████████▌ | 198/230 [2:34:51<25:43, 48.23s/it]                                                    86%|████████▌ | 198/230 [2:34:51<25:43, 48.23s/it] 87%|████████▋ | 199/230 [2:35:40<25:01, 48.45s/it]                                                    87%|████████▋ | 199/230 [2:35:40<25:01, 48.45s/it] 87%|████████▋ | 200/230 [2:36:25<23:40, 47.36s/it]                                                    87%|████████▋ | 200/230 [2:36:25<23:40, 47.36s/it]Saving model checkpoint to /scratch/axs7716Arshcentaur-ptsd-finetuned_5e-05_7264_1_1_8_0.01_10/checkpoint-200
loading configuration file config.json from cache at /home/axs7716/.cache/huggingface/hub/models--unsloth--Meta-Llama-3.1-70B-bnb-4bit/snapshots/a009b8db2439814febe725486a5ed388f12a8744/config.json
Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "dtype": "bfloat16",
  "eos_token_id": 128001,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 8192,
  "initializer_range": 0.02,
  "intermediate_size": 28672,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 64,
  "num_hidden_layers": 80,
  "num_key_value_heads": 8,
  "pad_token_id": 128004,
  "pretraining_tp": 1,
  "quantization_config": {
    "_load_in_4bit": true,
    "_load_in_8bit": false,
    "bnb_4bit_compute_dtype": "bfloat16",
    "bnb_4bit_quant_storage": "uint8",
    "bnb_4bit_quant_type": "nf4",
    "bnb_4bit_use_double_quant": true,
    "llm_int8_enable_fp32_cpu_offload": false,
    "llm_int8_has_fp16_weight": false,
    "llm_int8_skip_modules": null,
    "llm_int8_threshold": 6.0,
    "load_in_4bit": true,
    "load_in_8bit": false,
    "quant_method": "bitsandbytes"
  },
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 8.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "unsloth_version": "2024.9",
  "use_cache": true,
  "vocab_size": 128256
}

 87%|████████▋ | 201/230 [2:37:15<23:17, 48.18s/it]                                                    87%|████████▋ | 201/230 [2:37:15<23:17, 48.18s/it] 88%|████████▊ | 202/230 [2:38:04<22:42, 48.67s/it]                                                    88%|████████▊ | 202/230 [2:38:04<22:42, 48.67s/it] 88%|████████▊ | 203/230 [2:38:49<21:17, 47.31s/it]                                                    88%|████████▊ | 203/230 [2:38:49<21:17, 47.31s/it] 89%|████████▊ | 204/230 [2:39:31<19:49, 45.76s/it]                                                    89%|████████▊ | 204/230 [2:39:31<19:49, 45.76s/it] 89%|████████▉ | 205/230 [2:40:19<19:24, 46.59s/it]                                                    89%|████████▉ | 205/230 [2:40:19<19:24, 46.59s/it] 90%|████████▉ | 206/230 [2:41:05<18:34, 46.45s/it]                                                    90%|████████▉ | 206/230 [2:41:05<18:34, 46.45s/it] 90%|█████████ | 207/230 [2:41:38<16:10, 42.19s/it]                                                    90%|█████████ | 207/230 [2:41:38<16:10, 42.19s/it] 90%|█████████ | 208/230 [2:42:29<16:29, 44.98s/it]                                                    90%|█████████ | 208/230 [2:42:29<16:29, 44.98s/it] 91%|█████████ | 209/230 [2:43:16<15:55, 45.49s/it]                                                    91%|█████████ | 209/230 [2:43:16<15:55, 45.49s/it] 91%|█████████▏| 210/230 [2:44:04<15:25, 46.27s/it]                                                    91%|█████████▏| 210/230 [2:44:04<15:25, 46.27s/it] 92%|█████████▏| 211/230 [2:44:52<14:47, 46.71s/it]                                                    92%|█████████▏| 211/230 [2:44:52<14:47, 46.71s/it] 92%|█████████▏| 212/230 [2:45:42<14:21, 47.85s/it]                                                    92%|█████████▏| 212/230 [2:45:42<14:21, 47.85s/it] 93%|█████████▎| 213/230 [2:46:30<13:32, 47.82s/it]                                                    93%|█████████▎| 213/230 [2:46:30<13:32, 47.82s/it] 93%|█████████▎| 214/230 [2:47:16<12:35, 47.21s/it]                                                    93%|█████████▎| 214/230 [2:47:16<12:35, 47.21s/it] 93%|█████████▎| 215/230 [2:48:03<11:48, 47.20s/it]                                                    93%|█████████▎| 215/230 [2:48:03<11:48, 47.20s/it] 94%|█████████▍| 216/230 [2:48:50<10:59, 47.09s/it]                                                    94%|█████████▍| 216/230 [2:48:50<10:59, 47.09s/it] 94%|█████████▍| 217/230 [2:49:38<10:16, 47.45s/it]                                                    94%|█████████▍| 217/230 [2:49:38<10:16, 47.45s/it] 95%|█████████▍| 218/230 [2:50:25<09:27, 47.27s/it]                                                    95%|█████████▍| 218/230 [2:50:25<09:27, 47.27s/it] 95%|█████████▌| 219/230 [2:51:10<08:32, 46.63s/it]                                                    95%|█████████▌| 219/230 [2:51:10<08:32, 46.63s/it] 96%|█████████▌| 220/230 [2:51:58<07:50, 47.05s/it]                                                    96%|█████████▌| 220/230 [2:51:58<07:50, 47.05s/it] 96%|█████████▌| 221/230 [2:52:46<07:05, 47.26s/it]                                                    96%|█████████▌| 221/230 [2:52:46<07:05, 47.26s/it] 97%|█████████▋| 222/230 [2:53:36<06:26, 48.29s/it]                                                    97%|█████████▋| 222/230 [2:53:36<06:26, 48.29s/it] 97%|█████████▋| 223/230 [2:54:21<05:30, 47.20s/it]                                                    97%|█████████▋| 223/230 [2:54:21<05:30, 47.20s/it] 97%|█████████▋| 224/230 [2:55:08<04:42, 47.12s/it]                                                    97%|█████████▋| 224/230 [2:55:08<04:42, 47.12s/it] 98%|█████████▊| 225/230 [2:55:56<03:57, 47.44s/it]                                                    98%|█████████▊| 225/230 [2:55:56<03:57, 47.44s/it] 98%|█████████▊| 226/230 [2:56:38<03:03, 45.83s/it]                                                    98%|█████████▊| 226/230 [2:56:38<03:03, 45.83s/it] 99%|█████████▊| 227/230 [2:57:29<02:21, 47.23s/it]                                                    99%|█████████▊| 227/230 [2:57:29<02:21, 47.23s/it] 99%|█████████▉| 228/230 [2:58:18<01:35, 47.95s/it]                                                    99%|█████████▉| 228/230 [2:58:18<01:35, 47.95s/it]100%|█████████▉| 229/230 [2:59:04<00:47, 47.14s/it]                                                   100%|█████████▉| 229/230 [2:59:04<00:47, 47.14s/it]100%|██████████| 230/230 [2:59:34<00:00, 42.22s/it]                                                   100%|██████████| 230/230 [2:59:34<00:00, 42.22s/it]Saving model checkpoint to /scratch/axs7716Arshcentaur-ptsd-finetuned_5e-05_7264_1_1_8_0.01_10/checkpoint-230
loading configuration file config.json from cache at /home/axs7716/.cache/huggingface/hub/models--unsloth--Meta-Llama-3.1-70B-bnb-4bit/snapshots/a009b8db2439814febe725486a5ed388f12a8744/config.json
Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "dtype": "bfloat16",
  "eos_token_id": 128001,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 8192,
  "initializer_range": 0.02,
  "intermediate_size": 28672,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 64,
  "num_hidden_layers": 80,
  "num_key_value_heads": 8,
  "pad_token_id": 128004,
  "pretraining_tp": 1,
  "quantization_config": {
    "_load_in_4bit": true,
    "_load_in_8bit": false,
    "bnb_4bit_compute_dtype": "bfloat16",
    "bnb_4bit_quant_storage": "uint8",
    "bnb_4bit_quant_type": "nf4",
    "bnb_4bit_use_double_quant": true,
    "llm_int8_enable_fp32_cpu_offload": false,
    "llm_int8_has_fp16_weight": false,
    "llm_int8_skip_modules": null,
    "llm_int8_threshold": 6.0,
    "load_in_4bit": true,
    "load_in_8bit": false,
    "quant_method": "bitsandbytes"
  },
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 8.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "unsloth_version": "2024.9",
  "use_cache": true,
  "vocab_size": 128256
}



Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 230/230 [2:59:35<00:00, 42.22s/it]100%|██████████| 230/230 [2:59:35<00:00, 46.85s/it]
Saving model checkpoint to /scratch/axs7716Arshcentaur-ptsd-finetuned_5e-05_7264_1_1_8_0.01_10
loading configuration file config.json from cache at /home/axs7716/.cache/huggingface/hub/models--unsloth--Meta-Llama-3.1-70B-bnb-4bit/snapshots/a009b8db2439814febe725486a5ed388f12a8744/config.json
Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "dtype": "bfloat16",
  "eos_token_id": 128001,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 8192,
  "initializer_range": 0.02,
  "intermediate_size": 28672,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 64,
  "num_hidden_layers": 80,
  "num_key_value_heads": 8,
  "pad_token_id": 128004,
  "pretraining_tp": 1,
  "quantization_config": {
    "_load_in_4bit": true,
    "_load_in_8bit": false,
    "bnb_4bit_compute_dtype": "bfloat16",
    "bnb_4bit_quant_storage": "uint8",
    "bnb_4bit_quant_type": "nf4",
    "bnb_4bit_use_double_quant": true,
    "llm_int8_enable_fp32_cpu_offload": false,
    "llm_int8_has_fp16_weight": false,
    "llm_int8_skip_modules": null,
    "llm_int8_threshold": 6.0,
    "load_in_4bit": true,
    "load_in_8bit": false,
    "quant_method": "bitsandbytes"
  },
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 8.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "unsloth_version": "2024.9",
  "use_cache": true,
  "vocab_size": 128256
}

loading configuration file config.json from cache at /home/axs7716/.cache/huggingface/hub/models--unsloth--Meta-Llama-3.1-70B-bnb-4bit/snapshots/a009b8db2439814febe725486a5ed388f12a8744/config.json
Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "dtype": "bfloat16",
  "eos_token_id": 128001,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 8192,
  "initializer_range": 0.02,
  "intermediate_size": 28672,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 64,
  "num_hidden_layers": 80,
  "num_key_value_heads": 8,
  "pad_token_id": 128004,
  "pretraining_tp": 1,
  "quantization_config": {
    "_load_in_4bit": true,
    "_load_in_8bit": false,
    "bnb_4bit_compute_dtype": "bfloat16",
    "bnb_4bit_quant_storage": "uint8",
    "bnb_4bit_quant_type": "nf4",
    "bnb_4bit_use_double_quant": true,
    "llm_int8_enable_fp32_cpu_offload": false,
    "llm_int8_has_fp16_weight": false,
    "llm_int8_skip_modules": null,
    "llm_int8_threshold": 6.0,
    "load_in_4bit": true,
    "load_in_8bit": false,
    "quant_method": "bitsandbytes"
  },
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 8.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "unsloth_version": "2024.9",
  "use_cache": true,
  "vocab_size": 128256
}

loading configuration file config.json from cache at /home/axs7716/.cache/huggingface/hub/models--unsloth--Meta-Llama-3.1-70B-bnb-4bit/snapshots/a009b8db2439814febe725486a5ed388f12a8744/config.json
Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "dtype": "bfloat16",
  "eos_token_id": 128001,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 8192,
  "initializer_range": 0.02,
  "intermediate_size": 28672,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 64,
  "num_hidden_layers": 80,
  "num_key_value_heads": 8,
  "pad_token_id": 128004,
  "pretraining_tp": 1,
  "quantization_config": {
    "_load_in_4bit": true,
    "_load_in_8bit": false,
    "bnb_4bit_compute_dtype": "bfloat16",
    "bnb_4bit_quant_storage": "uint8",
    "bnb_4bit_quant_type": "nf4",
    "bnb_4bit_use_double_quant": true,
    "llm_int8_enable_fp32_cpu_offload": false,
    "llm_int8_has_fp16_weight": false,
    "llm_int8_skip_modules": null,
    "llm_int8_threshold": 6.0,
    "load_in_4bit": true,
    "load_in_8bit": false,
    "quant_method": "bitsandbytes"
  },
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 8.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "unsloth_version": "2024.9",
  "use_cache": true,
  "vocab_size": 128256
}

loading configuration file config.json from cache at /home/axs7716/.cache/huggingface/hub/models--unsloth--Meta-Llama-3.1-70B-bnb-4bit/snapshots/a009b8db2439814febe725486a5ed388f12a8744/config.json
Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "dtype": "bfloat16",
  "eos_token_id": 128001,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 8192,
  "initializer_range": 0.02,
  "intermediate_size": 28672,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 64,
  "num_hidden_layers": 80,
  "num_key_value_heads": 8,
  "pad_token_id": 128004,
  "pretraining_tp": 1,
  "quantization_config": {
    "_load_in_4bit": true,
    "_load_in_8bit": false,
    "bnb_4bit_compute_dtype": "bfloat16",
    "bnb_4bit_quant_storage": "uint8",
    "bnb_4bit_quant_type": "nf4",
    "bnb_4bit_use_double_quant": true,
    "llm_int8_enable_fp32_cpu_offload": false,
    "llm_int8_has_fp16_weight": false,
    "llm_int8_skip_modules": null,
    "llm_int8_threshold": 6.0,
    "load_in_4bit": true,
    "load_in_8bit": false,
    "quant_method": "bitsandbytes"
  },
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 8.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "unsloth_version": "2024.9",
  "use_cache": true,
  "vocab_size": 128256
}

loading configuration file config.json from cache at /home/axs7716/.cache/huggingface/hub/models--unsloth--Meta-Llama-3.1-70B-bnb-4bit/snapshots/a009b8db2439814febe725486a5ed388f12a8744/config.json
Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "dtype": "bfloat16",
  "eos_token_id": 128001,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 8192,
  "initializer_range": 0.02,
  "intermediate_size": 28672,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 64,
  "num_hidden_layers": 80,
  "num_key_value_heads": 8,
  "pad_token_id": 128004,
  "pretraining_tp": 1,
  "quantization_config": {
    "_load_in_4bit": true,
    "_load_in_8bit": false,
    "bnb_4bit_compute_dtype": "bfloat16",
    "bnb_4bit_quant_storage": "uint8",
    "bnb_4bit_quant_type": "nf4",
    "bnb_4bit_use_double_quant": true,
    "llm_int8_enable_fp32_cpu_offload": false,
    "llm_int8_has_fp16_weight": false,
    "llm_int8_skip_modules": null,
    "llm_int8_threshold": 6.0,
    "load_in_4bit": true,
    "load_in_8bit": false,
    "quant_method": "bitsandbytes"
  },
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 8.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "unsloth_version": "2024.9",
  "use_cache": true,
  "vocab_size": 128256
}

loading weights file model.safetensors from cache at /home/axs7716/.cache/huggingface/hub/models--unsloth--Meta-Llama-3.1-70B-bnb-4bit/snapshots/a009b8db2439814febe725486a5ed388f12a8744/model.safetensors.index.json
Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.
Generate config GenerationConfig {
  "bos_token_id": 128000,
  "eos_token_id": 128001,
  "pad_token_id": 128004
}

target_dtype {target_dtype} is replaced by `CustomDtype.INT4` for 4-bit BnB quantization
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:01<00:05,  1.16s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.17s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.17s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.18s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:05<00:01,  1.17s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.01s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.09s/it]
loading configuration file generation_config.json from cache at /home/axs7716/.cache/huggingface/hub/models--unsloth--Meta-Llama-3.1-70B-bnb-4bit/snapshots/a009b8db2439814febe725486a5ed388f12a8744/generation_config.json
Generate config GenerationConfig {
  "bos_token_id": 128000,
  "do_sample": true,
  "eos_token_id": 128001,
  "max_length": 131072,
  "pad_token_id": 128004,
  "temperature": 0.6,
  "top_p": 0.9
}

Could not locate the custom_generate/generate.py inside unsloth/Meta-Llama-3.1-70B-bnb-4bit.
Device set to use cuda:0

2025-11-27 14:19:46.137401: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-27 14:19:46.194991: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-27 14:24:54.406456: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-27 14:54:59.192217: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-27 14:54:59.241773: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-27 15:00:32.593336: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-27 15:19:08.141545: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-27 15:19:08.144977: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-27 15:19:08.157670: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-27 15:19:08.173690: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-27 15:19:08.192567: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-27 15:19:08.196046: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-27 15:19:08.206346: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-27 15:19:08.222698: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-27 15:24:25.123314: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-27 15:24:25.125307: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-27 15:24:26.868824: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-27 15:24:28.454356: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Map:   0%|          | 0/181 [00:00<?, ? examples/s]Map:   0%|          | 0/181 [00:00<?, ? examples/s]Map:   0%|          | 0/181 [00:00<?, ? examples/s]Map:   0%|          | 0/181 [00:00<?, ? examples/s]Map: 100%|██████████| 181/181 [00:00<00:00, 191.83 examples/s]Map: 100%|██████████| 181/181 [00:00<00:00, 194.47 examples/s]Map: 100%|██████████| 181/181 [00:01<00:00, 106.90 examples/s]
Map: 100%|██████████| 181/181 [00:01<00:00, 107.68 examples/s]
Map:   0%|          | 0/61 [00:00<?, ? examples/s]Map:   0%|          | 0/61 [00:00<?, ? examples/s]Map: 100%|██████████| 181/181 [00:01<00:00, 140.69 examples/s]Map: 100%|██████████| 181/181 [00:01<00:00, 140.31 examples/s]Map: 100%|██████████| 181/181 [00:01<00:00, 107.88 examples/s]
Map: 100%|██████████| 181/181 [00:01<00:00, 107.88 examples/s]
Map:   0%|          | 0/61 [00:00<?, ? examples/s]Map:   0%|          | 0/61 [00:00<?, ? examples/s]Map: 100%|██████████| 61/61 [00:01<00:00, 50.19 examples/s]Map: 100%|██████████| 61/61 [00:01<00:00, 51.63 examples/s]Map: 100%|██████████| 61/61 [00:01<00:00, 36.47 examples/s]
Map: 100%|██████████| 61/61 [00:01<00:00, 35.74 examples/s]
Map: 100%|██████████| 61/61 [00:00<00:00, 62.10 examples/s]Map: 100%|██████████| 61/61 [00:00<00:00, 61.95 examples/s]Map: 100%|██████████| 61/61 [00:01<00:00, 48.23 examples/s]
Map: 100%|██████████| 61/61 [00:01<00:00, 48.23 examples/s]
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.
The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.
The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.
The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.
/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/transformers/quantizers/auto.py:239: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.
  warnings.warn(warning_msg)
/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/transformers/quantizers/auto.py:239: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.
  warnings.warn(warning_msg)
/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/transformers/quantizers/auto.py:239: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.
  warnings.warn(warning_msg)
/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/transformers/quantizers/auto.py:239: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.
  warnings.warn(warning_msg)
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:04<00:22,  4.49s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:04<00:22,  4.53s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:04<00:22,  4.54s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:04<00:23,  4.62s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:10<00:20,  5.10s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:10<00:20,  5.11s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:10<00:20,  5.11s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:10<00:20,  5.15s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:15<00:15,  5.25s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:15<00:15,  5.28s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:15<00:15,  5.25s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:15<00:15,  5.30s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:21<00:10,  5.38s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:21<00:10,  5.38s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:21<00:10,  5.42s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:21<00:10,  5.47s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:26<00:05,  5.23s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:26<00:05,  5.25s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:26<00:05,  5.27s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:26<00:05,  5.32s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:28<00:00,  4.29s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:28<00:00,  4.75s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:28<00:00,  4.29s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:28<00:00,  4.75s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:28<00:00,  4.31s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:28<00:00,  4.76s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:28<00:00,  4.39s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:28<00:00,  4.83s/it]
/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/peft/mapping_func.py:72: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.
  warnings.warn(
/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!
  warnings.warn(
/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/peft/mapping_func.py:72: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.
  warnings.warn(
/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!
  warnings.warn(
/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/peft/mapping_func.py:72: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.
  warnings.warn(
/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!
  warnings.warn(
/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/peft/mapping_func.py:72: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.
  warnings.warn(
/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!
  warnings.warn(
/home/axs7716/my_model/Finetuning_V4-deepseek.py:235: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
/home/axs7716/my_model/Finetuning_V4-deepseek.py:235: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
/home/axs7716/my_model/Finetuning_V4-deepseek.py:235: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
/home/axs7716/my_model/Finetuning_V4-deepseek.py:235: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.
Using auto half precision backend
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.
Gradient accumulation steps mismatch: GradientAccumulationPlugin has 1, DeepSpeed config has 4. Using DeepSpeed's value.
***** Running training *****
  Num examples = 181
  Num Epochs = 10
  Instantaneous batch size per device = 2
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 4
  Total optimization steps = 60
  Number of trainable parameters = 103,546,880
  0%|          | 0/60 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
  2%|▏         | 1/60 [02:15<2:13:14, 135.50s/it]                                                   2%|▏         | 1/60 [02:15<2:13:14, 135.50s/it]  3%|▎         | 2/60 [04:36<2:14:16, 138.91s/it]                                                   3%|▎         | 2/60 [04:36<2:14:16, 138.91s/it]  5%|▌         | 3/60 [06:37<2:03:51, 130.38s/it]                                                   5%|▌         | 3/60 [06:37<2:03:51, 130.38s/it]  7%|▋         | 4/60 [08:50<2:02:51, 131.64s/it]                                                   7%|▋         | 4/60 [08:50<2:02:51, 131.64s/it]  8%|▊         | 5/60 [11:06<2:01:57, 133.04s/it]                                                   8%|▊         | 5/60 [11:06<2:01:57, 133.04s/it] 10%|█         | 6/60 [12:53<1:51:47, 124.21s/it]                                                  10%|█         | 6/60 [12:53<1:51:47, 124.21s/it] 12%|█▏        | 7/60 [15:07<1:52:36, 127.49s/it]                                                  12%|█▏        | 7/60 [15:07<1:52:36, 127.49s/it] 13%|█▎        | 8/60 [17:27<1:53:50, 131.36s/it]                                                  13%|█▎        | 8/60 [17:27<1:53:50, 131.36s/it] 15%|█▌        | 9/60 [19:40<1:52:14, 132.04s/it]                                                  15%|█▌        | 9/60 [19:40<1:52:14, 132.04s/it] 17%|█▋        | 10/60 [21:53<1:50:11, 132.23s/it]                                                   17%|█▋        | 10/60 [21:53<1:50:11, 132.23s/it] 18%|█▊        | 11/60 [24:13<1:49:57, 134.64s/it]                                                   18%|█▊        | 11/60 [24:13<1:49:57, 134.64s/it] 20%|██        | 12/60 [25:53<1:39:18, 124.14s/it]                                                   20%|██        | 12/60 [25:53<1:39:18, 124.14s/it] 22%|██▏       | 13/60 [28:06<1:39:16, 126.74s/it]                                                   22%|██▏       | 13/60 [28:06<1:39:16, 126.74s/it] 23%|██▎       | 14/60 [30:17<1:38:07, 128.00s/it]                                                   23%|██▎       | 14/60 [30:17<1:38:07, 128.00s/it] 25%|██▌       | 15/60 [32:35<1:38:24, 131.21s/it]                                                   25%|██▌       | 15/60 [32:35<1:38:24, 131.21s/it] 27%|██▋       | 16/60 [34:57<1:38:34, 134.42s/it]                                                   27%|██▋       | 16/60 [34:57<1:38:34, 134.42s/it] 28%|██▊       | 17/60 [37:11<1:36:09, 134.18s/it]                                                   28%|██▊       | 17/60 [37:11<1:36:09, 134.18s/it] 30%|███       | 18/60 [38:51<1:26:43, 123.90s/it]                                                   30%|███       | 18/60 [38:51<1:26:43, 123.90s/it] 32%|███▏      | 19/60 [41:04<1:26:33, 126.66s/it]                                                   32%|███▏      | 19/60 [41:04<1:26:33, 126.66s/it] 33%|███▎      | 20/60 [43:16<1:25:33, 128.34s/it]                                                   33%|███▎      | 20/60 [43:16<1:25:33, 128.34s/it] 35%|███▌      | 21/60 [45:31<1:24:36, 130.17s/it]                                                   35%|███▌      | 21/60 [45:31<1:24:36, 130.17s/it] 37%|███▋      | 22/60 [47:43<1:22:56, 130.95s/it]                                                   37%|███▋      | 22/60 [47:43<1:22:56, 130.95s/it] 38%|███▊      | 23/60 [50:04<1:22:32, 133.86s/it]                                                   38%|███▊      | 23/60 [50:04<1:22:32, 133.86s/it] 40%|████      | 24/60 [51:51<1:15:28, 125.80s/it]                                                   40%|████      | 24/60 [51:51<1:15:28, 125.80s/it] 42%|████▏     | 25/60 [54:04<1:14:41, 128.04s/it]                                                   42%|████▏     | 25/60 [54:04<1:14:41, 128.04s/it] 43%|████▎     | 26/60 [56:23<1:14:26, 131.37s/it]                                                   43%|████▎     | 26/60 [56:23<1:14:26, 131.37s/it] 45%|████▌     | 27/60 [58:33<1:11:55, 130.77s/it]                                                   45%|████▌     | 27/60 [58:33<1:11:55, 130.77s/it] 47%|████▋     | 28/60 [1:00:45<1:10:01, 131.30s/it]                                                     47%|████▋     | 28/60 [1:00:45<1:10:01, 131.30s/it] 48%|████▊     | 29/60 [1:03:05<1:09:09, 133.87s/it]                                                     48%|████▊     | 29/60 [1:03:05<1:09:09, 133.87s/it] 50%|█████     | 30/60 [1:04:45<1:01:47, 123.58s/it]                                                     50%|█████     | 30/60 [1:04:45<1:01:47, 123.58s/it] 52%|█████▏    | 31/60 [1:06:58<1:01:04, 126.35s/it]                                                     52%|█████▏    | 31/60 [1:06:58<1:01:04, 126.35s/it] 53%|█████▎    | 32/60 [1:09:25<1:01:52, 132.60s/it]                                                     53%|█████▎    | 32/60 [1:09:25<1:01:52, 132.60s/it] 55%|█████▌    | 33/60 [1:11:38<59:42, 132.69s/it]                                                     55%|█████▌    | 33/60 [1:11:38<59:42, 132.69s/it] 57%|█████▋    | 34/60 [1:13:51<57:32, 132.78s/it]                                                   57%|█████▋    | 34/60 [1:13:51<57:32, 132.78s/it] 58%|█████▊    | 35/60 [1:16:03<55:13, 132.55s/it]                                                   58%|█████▊    | 35/60 [1:16:03<55:13, 132.55s/it] 60%|██████    | 36/60 [1:17:43<49:10, 122.94s/it]                                                   60%|██████    | 36/60 [1:17:43<49:10, 122.94s/it] 62%|██████▏   | 37/60 [1:20:02<49:00, 127.84s/it]                                                   62%|██████▏   | 37/60 [1:20:02<49:00, 127.84s/it] 63%|██████▎   | 38/60 [1:22:14<47:17, 129.00s/it]                                                   63%|██████▎   | 38/60 [1:22:14<47:17, 129.00s/it] 65%|██████▌   | 39/60 [1:24:27<45:33, 130.18s/it]                                                   65%|██████▌   | 39/60 [1:24:27<45:33, 130.18s/it] 67%|██████▋   | 40/60 [1:26:41<43:44, 131.23s/it]                                                   67%|██████▋   | 40/60 [1:26:41<43:44, 131.23s/it] 68%|██████▊   | 41/60 [1:28:53<41:41, 131.63s/it]                                                   68%|██████▊   | 41/60 [1:28:53<41:41, 131.63s/it] 70%|███████   | 42/60 [1:30:40<37:12, 124.04s/it]                                                   70%|███████   | 42/60 [1:30:40<37:12, 124.04s/it][rank2]: Traceback (most recent call last):
[rank2]:   File "/home/axs7716/my_model/Finetuning_V4-deepseek.py", line 305, in <module>
[rank2]:     main(model_args, data_args, training_args)
[rank2]:   File "/home/axs7716/my_model/Finetuning_V4-deepseek.py", line 248, in main
[rank2]:     trainer.train(resume_from_checkpoint=None)
[rank2]:   File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/transformers/trainer.py", line 2325, in train
[rank2]:     return inner_training_loop(
[rank2]:            ^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/transformers/trainer.py", line 2674, in _inner_training_loop
[rank2]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank2]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/transformers/trainer.py", line 4071, in training_step
[rank2]:     self.accelerator.backward(loss, **kwargs)
[rank2]:   File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/accelerate/accelerator.py", line 2732, in backward
[rank2]:     self.deepspeed_engine_wrapped.backward(loss, sync_gradients=self.sync_gradients, **kwargs)
[rank2]:   File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/accelerate/utils/deepspeed.py", line 270, in backward
[rank2]:     self.engine.backward(loss, **kwargs)
[rank2]:   File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
[rank2]:     ret_val = func(*args, **kwargs)
[rank2]:               ^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 2356, in backward
[rank2]:     self._do_optimizer_backward(loss, retain_graph)
[rank2]:   File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 2297, in _do_optimizer_backward
[rank2]:     self.optimizer.backward(loss, retain_graph=retain_graph)
[rank2]:   File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
[rank2]:     ret_val = func(*args, **kwargs)
[rank2]:               ^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/deepspeed/runtime/zero/stage3.py", line 2341, in backward
[rank2]:     self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)
[rank2]:   File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/deepspeed/runtime/fp16/loss_scaler.py", line 65, in backward
[rank2]:     scaled_loss.backward(retain_graph=retain_graph)
[rank2]:   File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
[rank2]:     torch.autograd.backward(
[rank2]:   File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
[rank2]:     _engine_run_backward(
[rank2]:   File "/home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
[rank2]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 9.87 GiB. GPU 2 has a total capacity of 79.19 GiB of which 9.07 GiB is free. Including non-PyTorch memory, this process has 70.09 GiB memory in use. Of the allocated memory 50.01 GiB is allocated by PyTorch, and 17.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank3]:[W1127 17:24:03.854952545 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=50, addr=[localhost]:56664, remote=[localhost]:29500): Connection reset by peer
Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:694 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x79ee7b97ab80 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ffd531 (0x79edce0cd531 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5ffe993 (0x79edce0ce993 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5fff4da (0x79edce0cf4da in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x79edce0ca1fe in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x3c8 (0x79ed8cc486b8 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdf0e6 (0x79ee814e90e6 in /home/axs7716/anaconda3/envs/arsh_env/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x79ee93e9caa4 in /lib/x86_64-linux-gnu/libc.so.6)
frame #8: <unknown function> + 0x129c6c (0x79ee93f29c6c in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[W1127 17:24:03.854940745 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=50, addr=[localhost]:56650, remote=[localhost]:29500): Connection reset by peer
Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:694 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7c58812d0b80 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ffd531 (0x7c57ce0cd531 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5ffe993 (0x7c57ce0ce993 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5fff4da (0x7c57ce0cf4da in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7c57ce0ca1fe in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x3c8 (0x7c578cc486b8 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdf0e6 (0x7c5883ce90e6 in /home/axs7716/anaconda3/envs/arsh_env/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x7c5893e9caa4 in /lib/x86_64-linux-gnu/libc.so.6)
frame #8: <unknown function> + 0x129c6c (0x7c5893f29c6c in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W1127 17:24:03.865464461 ProcessGroupNCCL.cpp:1771] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[rank1]:[W1127 17:24:03.865487471 ProcessGroupNCCL.cpp:1771] [PG ID 0 PG GUID 0(default_pg) Rank 1] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Connection reset by peer
[rank3]:[W1127 17:24:04.865703406 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=50, addr=[localhost]:56664, remote=[localhost]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:668 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x79ee7b97ab80 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ffd531 (0x79edce0cd531 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5ffddc2 (0x79edce0cddc2 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5fff8ce (0x79edce0cf8ce in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x79edce0ca1ee in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x3c8 (0x79ed8cc486b8 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdf0e6 (0x79ee814e90e6 in /home/axs7716/anaconda3/envs/arsh_env/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x79ee93e9caa4 in /lib/x86_64-linux-gnu/libc.so.6)
frame #8: <unknown function> + 0x129c6c (0x79ee93f29c6c in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W1127 17:24:04.871952585 ProcessGroupNCCL.cpp:1771] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank1]:[W1127 17:24:04.865752886 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=50, addr=[localhost]:56650, remote=[localhost]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:668 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7c58812d0b80 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ffd531 (0x7c57ce0cd531 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5ffddc2 (0x7c57ce0cddc2 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5fff8ce (0x7c57ce0cf8ce in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7c57ce0ca1ee in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x3c8 (0x7c578cc486b8 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdf0e6 (0x7c5883ce90e6 in /home/axs7716/anaconda3/envs/arsh_env/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x7c5893e9caa4 in /lib/x86_64-linux-gnu/libc.so.6)
frame #8: <unknown function> + 0x129c6c (0x7c5893f29c6c in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[W1127 17:24:04.872077324 ProcessGroupNCCL.cpp:1771] [PG ID 0 PG GUID 0(default_pg) Rank 1] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W1127 17:24:05.872192540 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=50, addr=[localhost]:56664, remote=[localhost]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:668 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x79ee7b97ab80 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ffd531 (0x79edce0cd531 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5ffddc2 (0x79edce0cddc2 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5fff8ce (0x79edce0cf8ce in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x79edce0ca1ee in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x3c8 (0x79ed8cc486b8 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdf0e6 (0x79ee814e90e6 in /home/axs7716/anaconda3/envs/arsh_env/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x79ee93e9caa4 in /lib/x86_64-linux-gnu/libc.so.6)
frame #8: <unknown function> + 0x129c6c (0x79ee93f29c6c in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W1127 17:24:05.878474958 ProcessGroupNCCL.cpp:1771] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank1]:[W1127 17:24:05.872346379 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=50, addr=[localhost]:56650, remote=[localhost]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:668 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7c58812d0b80 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ffd531 (0x7c57ce0cd531 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5ffddc2 (0x7c57ce0cddc2 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5fff8ce (0x7c57ce0cf8ce in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7c57ce0ca1ee in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x3c8 (0x7c578cc486b8 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdf0e6 (0x7c5883ce90e6 in /home/axs7716/anaconda3/envs/arsh_env/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x7c5893e9caa4 in /lib/x86_64-linux-gnu/libc.so.6)
frame #8: <unknown function> + 0x129c6c (0x7c5893f29c6c in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[W1127 17:24:05.878638007 ProcessGroupNCCL.cpp:1771] [PG ID 0 PG GUID 0(default_pg) Rank 1] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W1127 17:24:06.878663413 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=50, addr=[localhost]:56664, remote=[localhost]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:668 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x79ee7b97ab80 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ffd531 (0x79edce0cd531 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5ffddc2 (0x79edce0cddc2 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5fff8ce (0x79edce0cf8ce in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x79edce0ca1ee in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x3c8 (0x79ed8cc486b8 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdf0e6 (0x79ee814e90e6 in /home/axs7716/anaconda3/envs/arsh_env/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x79ee93e9caa4 in /lib/x86_64-linux-gnu/libc.so.6)
frame #8: <unknown function> + 0x129c6c (0x79ee93f29c6c in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W1127 17:24:06.883855577 ProcessGroupNCCL.cpp:1771] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W1127 17:24:07.884115412 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=50, addr=[localhost]:56664, remote=[localhost]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:668 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x79ee7b97ab80 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ffd531 (0x79edce0cd531 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5ffddc2 (0x79edce0cddc2 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5fff8ce (0x79edce0cf8ce in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x79edce0ca1ee in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x3c8 (0x79ed8cc486b8 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdf0e6 (0x79ee814e90e6 in /home/axs7716/anaconda3/envs/arsh_env/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x79ee93e9caa4 in /lib/x86_64-linux-gnu/libc.so.6)
frame #8: <unknown function> + 0x129c6c (0x79ee93f29c6c in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W1127 17:24:07.890358330 ProcessGroupNCCL.cpp:1771] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W1127 17:24:08.890597725 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=50, addr=[localhost]:56664, remote=[localhost]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:668 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x79ee7b97ab80 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ffd531 (0x79edce0cd531 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5ffddc2 (0x79edce0cddc2 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5fff8ce (0x79edce0cf8ce in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x79edce0ca1ee in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x3c8 (0x79ed8cc486b8 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdf0e6 (0x79ee814e90e6 in /home/axs7716/anaconda3/envs/arsh_env/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x79ee93e9caa4 in /lib/x86_64-linux-gnu/libc.so.6)
frame #8: <unknown function> + 0x129c6c (0x79ee93f29c6c in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W1127 17:24:08.896866503 ProcessGroupNCCL.cpp:1771] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W1127 17:24:09.897153578 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=50, addr=[localhost]:56664, remote=[localhost]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:668 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x79ee7b97ab80 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ffd531 (0x79edce0cd531 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5ffddc2 (0x79edce0cddc2 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5fff8ce (0x79edce0cf8ce in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x79edce0ca1ee in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x3c8 (0x79ed8cc486b8 in /home/axs7716/anaconda3/envs/arsh_env/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdf0e6 (0x79ee814e90e6 in /home/axs7716/anaconda3/envs/arsh_env/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x79ee93e9caa4 in /lib/x86_64-linux-gnu/libc.so.6)
frame #8: <unknown function> + 0x129c6c (0x79ee93f29c6c in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W1127 17:24:09.903400327 ProcessGroupNCCL.cpp:1771] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
